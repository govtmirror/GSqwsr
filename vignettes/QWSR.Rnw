%\VignetteIndexEntry{Introduction to the GSqwsr package}
%\VignetteEngine{knitr::knitr}
%\VignetteDepends{}
%\VignetteSuggests{xtable}
%\VignettePackage{GSqwsr}

\documentclass[a4paper,11pt]{article}

\usepackage{amsmath}
\usepackage{times}
\usepackage{hyperref}
\usepackage[numbers, round]{natbib}
\usepackage[american]{babel}
\usepackage{authblk}
\usepackage{subfig}
\usepackage{placeins}
\usepackage{footnote}
\usepackage{tabularx}
\renewcommand\Affilfont{\itshape\small}

\renewcommand{\topfraction}{0.85}
\renewcommand{\textfraction}{0.1}
\usepackage{graphicx}


\textwidth=6.2in
\textheight=8.5in
\parskip=.3cm
\oddsidemargin=.1in
\evensidemargin=.1in
\headheight=-.3in

%------------------------------------------------------------
% newcommand
%------------------------------------------------------------
\newcommand{\scscst}{\scriptscriptstyle}
\newcommand{\scst}{\scriptstyle}
\newcommand{\Robject}[1]{{\texttt{#1}}}
\newcommand{\Rfunction}[1]{{\texttt{#1}}}
\newcommand{\Rclass}[1]{\textit{#1}}
\newcommand{\Rpackage}[1]{\textit{#1}}
\newcommand{\Rexpression}[1]{\texttt{#1}}
\newcommand{\Rmethod}[1]{{\texttt{#1}}}
\newcommand{\Rfunarg}[1]{{\texttt{#1}}}

\begin{document}


<<openLibrary, echo=FALSE>>=
library(xtable)
options(continue=" ")
options(width=60)
library(knitr)

@


%------------------------------------------------------------
\title{The GSqwsr R package}
%------------------------------------------------------------
\author[1]{Laura De Cicco}
\author[1]{Steve Corsi}
\author[1]{Austin Baldwin}
\affil[1]{United States Geological Survey}


<<include=TRUE ,echo=FALSE,eval=TRUE>>=
opts_chunk$set(highlight=TRUE, tidy=TRUE, keep.space=TRUE, keep.blank.space=FALSE, keep.comment=TRUE, tidy=FALSE,comment="")
knit_hooks$set(inline = function(x) {
   if (is.numeric(x)) round(x, 3)})
knit_hooks$set(crop = hook_pdfcrop)

@


\maketitle
\tableofcontents

%------------------------------------------------------------
\section{Introduction to GSqwsr package}
%------------------------------------------------------------ 
The GSqwsr (USGS water quality surrogate regressions) package was designed to simplify the process of gathering water quality sample data and unit surrogate data, running a stepwise regression using the USGSwsQW censReg function, and analyzing those results. This vignette will first show a general overview workflow  (\ref{sec:workflow}), then a more detailed description of the workflow with working examples (\ref{sec:details}).

%------------------------------------------------------------
\section{General Workflow}
\label{sec:workflow}
%------------------------------------------------------------ 

<<start,eval = FALSE>>=
library("GSqwsr")

#Sample data included with package:
DTComplete <- StLouisDT
UV <- StLouisUV
QWcodes <- StLouisQWcodes
siteINFO <- StLouisInfo

investigateResponse <- "SuspSed"
transformResponse <- "lognormal"

DT <- DTComplete[c(investigateResponse,
                   getPredictVariables(names(UV)), 
                   "decYear","sinDY","cosDY","datetime")]
DT <- na.omit(DT)

predictVariables <- names(DT)[-which(names(DT) 
                  %in% c(investigateResponse,"datetime","decYear"))]


#Check predictor variables
predictVariableScatterPlots(DT,investigateResponse)

# Create 'kitchen sink' formula:
kitchenSink <- createFullFormula(DT,investigateResponse)

#Run stepwise regression with "kitchen sink" as upper bound:
returnPrelim <- prelimModelDev(DT,investigateResponse,kitchenSink,
                               "BIC", #Other option is "AIC"
                               transformResponse)

steps <- returnPrelim$steps
modelResult <- returnPrelim$modelInformation
modelReturn <- returnPrelim$DT.mod

# Analyze steps found:
plotSteps(steps,DT,transformResponse)
analyzeSteps(steps, investigateResponse,siteINFO)

# Analyze model produced from stepwise regression:
resultPlots(DT,modelReturn,siteINFO)
resultResidPlots(DT,modelReturn,siteINFO)

# Create prediction plots
predictionPlot(UV,DT,modelReturn,siteINFO=siteINFO)

@


%------------------------------------------------------------
\section{Workflow Details}
\label{sec:details}
%------------------------------------------------------------
In this section, we will step through the basic workflow.

%------------------------------------------------------------
\subsection{Data Retrieval}
%------------------------------------------------------------
Data retrieval is currently supported by web service calls to the National Water Information Service (NWIS). The first step is to get the discrete sample data that the regressions are modeling. In this example, we will look at the St Louis River at Scanlon (USGS site ID 04024000). If we don't know the sample data that is available, we can use the whatQW function to discover that information. 

<<openGSqwsr,echo=TRUE,eval=FALSE>>=
library(GSqwsr)
@

<<openGSqwsrHidden,echo=FALSE,eval=TRUE, message=FALSE>>=
library(GSqwsr)
@


<<whatQW,echo=TRUE,eval=TRUE>>=

site <- "04024000"  
QWcodes <- whatQW(site, minCount=20)
head(QWcodes)
@

Most likely, there will be a known set of parameters that are to be modeled. If the parameter codes for these analytes are known, the data from NWIS can be accessed directly with the function importNWISqw. The following example shows the process, and then lists the column names returned in the QW dataframe.


<<importNWISqw,echo=TRUE,eval=FALSE>>=
pCodeQW <- c("00608","00613","00618","00631","00665",
             "00671","00940","62855","80154")
startDate <- "2011-03-17"
endDate <- ""
QW <- importNWISqw(site, params=pCodeQW, 
                   begin.date=startDate, end.date=endDate)
@

<<importNWISqwHidden,echo=FALSE,eval=TRUE>>=
pCodeQW <- c("00608","00613","00618","00631","00665",
             "00671","00940","62855","80154")
startDate <- "2011-04-22"
endDate <- ""
QW <- StLouisQW
@

<<qwColNames,echo=TRUE,eval=TRUE>>=
names(QW)
@


This brings the data in automatically as a `qw' object. This means that censoring information is embeded within each data point. If any processing needs to be done to the data, it might be easier to import the raw data first, then convert to 'qw' objects with the makeQWObjects function.

<<makeQWObjects,echo=TRUE,eval=FALSE>>=

QWRaw <- retrieveNWISqwData(site,pCodeQW,startDate,
                            endDate,expanded=TRUE)
QW <- makeQWObjects(QWRaw)
@

Next, the unit value data that will be used as surrogates for the analytes should be retrieved. If the parameters are not known, they can be discovered using the getDataAvailability function, filtering just the `uv' (unit value) data:

<<getDataAvailability,echo=TRUE,eval=TRUE>>=
UVcodes <- getDataAvailability(site)
UVcodes <- UVcodes[UVcodes$service == "uv",]
names(UVcodes)
UVcodes$parameter_cd
@

Finally, the unit value data can be retrieved with the getMultipleUV function. Because of the potentially large amount of data being returned, the web service call is automatically split into individual parameter codes.

<<getMultipleUV,echo=TRUE,eval=FALSE>>=
UVpCodes <- c("00010","00060","00095","00300","00400","63680")
UV <- getMultipleUV(site, startDate, endDate, UVpCodes)

@

<<getMultipleUVHidden,echo=FALSE,eval=TRUE>>=
UVpCodes <- c("00010","00060","00095","00300","00400","63680")
UV <- StLouisUV
@

<<uvColNames,echo=TRUE,eval=TRUE>>=
names(UV)
@


%------------------------------------------------------------
\subsection{Data Merging}
%------------------------------------------------------------
We now need to merge the sample and continuous data into one dataframe. This is accomplished using the mergeDatasets function.

<<mergeDatasets,echo=TRUE,eval=TRUE>>=
mergeReturn <- mergeDatasets(QW, UV, QWcodes)
DTComplete <- mergeReturn$DTComplete
QWcodes <- mergeReturn$QWcodes
@

The dataframe DTComplete contains a column of each of the discrete samples, and a column of the nearest (temporaly) unit value data. The function mergeDatasets has an argument called `max.diff'. The default is set to `2 hours', meaning that if the sample and continious data timestamps do not match, the merge will take the closest continious data within 2 hours. This value can be changed, see ?mergeNearest for more options.

%------------------------------------------------------------
\subsection{Data Investigation}
%------------------------------------------------------------

%------------------------------------------------------------
\subsubsection{Narrow down investigation}
%------------------------------------------------------------


We now want to narrow our investigation down to one analyte. Let us look at Chloride. First we will want a dataframe DT with just chloride and the unit values. We will call these the `prediciton values' because they will eventually be used to predict chloride.

<<getDT,echo=TRUE,eval=TRUE>>=
investigateResponse <- "Chloride"
predictionVariables <- getPredictVariables(names(UV))

DT <- DTComplete[c(investigateResponse,
                   predictionVariables, 
                   "decYear","sinDY","cosDY","datetime")]

names(DT)
@

For the regression, there can be no NA values in any of the columns. There are many ways in R to deal with this requirement. The easiest way to do it is remove any row that has any NA. This can be done as follows:

<<rmNADT,echo=TRUE,eval=TRUE>>=
DT <- na.omit(DT)
@

There may be other situations where you want to remove a column that contains the majority of the missing data.

%------------------------------------------------------------
\subsubsection{Plot variables}
%------------------------------------------------------------
There are a few tools included in this package to explore the data before performing the regression.

<<plotQQTransforms,echo=TRUE,eval=TRUE,fig.cap="plotQQTransforms">>=
plotQQTransforms(DT,investigateResponse)
@


<<predictVariableScatterPlots,echo=TRUE,eval=TRUE,fig.cap="predictVariableScatterPlots", message=FALSE>>=
predictVariableScatterPlots(DT,investigateResponse)
@

\FloatBarrier
%------------------------------------------------------------
\subsection{Stepwise Regression}
%------------------------------------------------------------
We are ready to perform a stepwise regression of the data to find the most significant variables to use in the model. This is accomlished with the prelimModelDev function. There are several inputs to this function. DT is the dataframe with all the predictor variables as well as the response we are investigating. We also need to define an upper bound for the stepwise regression to test. This is an equation with the most predictor variables, along with their transforms. If we want to use all possible variables, and all available transforms, we can use the equation createFullFormula (continuing with our Chloride example):

<<createFullFormula,echo=TRUE,eval=TRUE,echo=TRUE>>=
upperBoundFormula <- createFullFormula(DT,investigateResponse)
@

<<createFullFormula2,echo=TRUE,eval=TRUE,echo=FALSE,results='markup'>>=
substring(upperBoundFormula, first=0,last=59)
substring(upperBoundFormula, first=60,last=119)
@

The function will check if any data in DT has less than or equal to zero values. If so, a log transform is not included.

Now to use the stepwise regression within the prelimModelDev function:

<<prelimModelDev,echo=TRUE,eval=TRUE,echo=TRUE>>=
transformResponse <- "lognormal"

returnPrelim <- prelimModelDev(DT,
                 investigateResponse,
                 upperBoundFormula,
                 "BIC", #Other option is "AIC"
                 transformResponse)

steps <- returnPrelim$steps
modelResult <- returnPrelim$modelInformation
modelReturn <- returnPrelim$DT.mod
@

The output during the function shows the steps that the stepwise regression determined were ideal. 
\FloatBarrier

%------------------------------------------------------------
\subsection{Stepwise Regression Analysis}
%------------------------------------------------------------
It might be a good idea here to verify that the results from the stepwise regression are indeed what you want. The process can be observed using two functions: plotSteps and analyzeSteps.

\FloatBarrier

<<analyzeSteps,echo=TRUE,eval=TRUE,echo=TRUE,fig.cap="analyzeSteps">>=
siteINFO <- getSiteFileData(site, interactive=FALSE)
analyzeSteps(steps, investigateResponse,siteINFO)
@

\FloatBarrier


<<plotSteps,echo=TRUE,eval=TRUE,echo=TRUE,fig.cap="plotSteps">>=
plotSteps(steps,DT,transformResponse)
@

\FloatBarrier
%------------------------------------------------------------
\subsection{Model Analysis}
%------------------------------------------------------------
Finally, the package offers several ways to analyze the model results.

<<resultPlots,echo=TRUE,eval=TRUE,echo=TRUE,fig.cap="resultPlots">>=
resultPlots(DT,modelReturn,siteINFO)
@

\FloatBarrier

<<resultResidPlots,echo=TRUE,eval=TRUE,echo=TRUE,fig.cap="resultResidPlots">>=
resultResidPlots(DT,modelReturn,siteINFO)
@

\FloatBarrier

<<predictionPlot,echo=TRUE,eval=TRUE,echo=TRUE,fig.cap="predictionPlot">>=
predictionPlot(UV,DT,modelReturn,siteINFO=siteINFO)
@

\FloatBarrier

<<summaryPrintout,echo=TRUE,eval=TRUE,echo=TRUE>>=
summaryPrintout(modelReturn, siteINFO, saveOutput=FALSE,fileName)
@

\clearpage
\appendix

%------------------------------------------------------------ 
\section{Getting Started in R}
\label{sec:appendix1}
%------------------------------------------------------------ 
This section describes the options for downloading and installing the dataRetrieval package.

%------------------------------------------------------------
\subsection{New to R?}
%------------------------------------------------------------ 
If you are new to R, you will need to first install the latest version of R, which can be found here: \url{http://www.r-project.org/}.

There are many options for running and editing R code, one nice environment to learn R is RStudio. RStudio can be downloaded here: \url{http://rstudio.org/}. Once R and RStudio are installed, the dataRetrieval package needs to be installed as described in the next section.

At any time, you can get information about any function in R by typing a question mark before the functions name.  This will open a file (in RStudio, in the Help window) that describes the function, the required arguments, and provides working examples.

<<helpFunc,eval = FALSE>>=
library(GSqwsr)
?plotSteps
@

To see the raw code for a particular code, type the name of the function:
<<rawFunc,eval = FALSE>>=
plotSteps
@

%------------------------------------------------------------
\subsection{R User: Installing QWSR}
%------------------------------------------------------------ 
Before installing GSqwsr, the dependent packages must be first be installed:

<<installFromCran,eval = FALSE>>=
install.packages(c("XML", "lubridate", "akima", "KernSmooth",
                   "leaps", "car", "mvtnorm", "digest",
                   "relimp", "BSDA", "RODBC","memoise",
                   "boot","survival","splines","RColorBrewer",
                   "lattice","MASS"), dependencies=TRUE)
install.packages(c("USGSwsBase","USGSwsData","dataRetrieval",
                   "USGSwsGraphs","USGSwsStats",
                   "USGSwsQW","GSqwsr"), 
                 repos="http://usgs-r.github.com")
@


After installing the package, you need to open the library each time you re-start R.  This is done with the simple command:
<<openLibraryTest, eval=FALSE>>=
library(GSqwsr)
@




\end{document}
